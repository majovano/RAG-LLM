{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c063ae4f9334467caa68fe91dc853dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "27259830"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import datasets\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# R_NUMBER_SEED = 1234567 # Replace this with your own student number\n",
    "R_NUMBER_SEED = 928036 # my student number \n",
    "DOCS_TO_ADD = 1000\n",
    "query_documents = datasets.load_dataset(\"parquet\", data_files=\"./acl_anthology_queries.parquet\")[\"train\"]\n",
    "all_documents = datasets.load_dataset(\"parquet\", data_files=\"./acl_anthology_full.parquet\")[\"train\"]\n",
    "# Shuffle with seed and take only n docs\n",
    "shuffled_documents = all_documents.shuffle(seed=R_NUMBER_SEED)\n",
    "random_documents = shuffled_documents.select(range(DOCS_TO_ADD))\n",
    "# Concatenate relevant documents with random sample and shuffle again\n",
    "anthology_sample = datasets.concatenate_datasets([query_documents, random_documents]).shuffle(seed=R_NUMBER_SEED)\n",
    "# Export to Parquet to avoid downloading full anthology\n",
    "anthology_sample.to_parquet(\"./anthology_sample.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "queries = json.load(open(\"./acl_anthology_queries.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mjova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "def remove_stopwords(doc):\n",
    "    text = ' '.join([word for word in doc.split() if word.lower() not in stop_words])\n",
    "\n",
    "def preprocess_document(doc):\n",
    "    # Flatten dictionary and combine relevant text fields\n",
    "    text = f\"{doc.get('title', '')} {doc.get('abstract', '')} {doc.get('full_text', '')}\"\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess_documents(documents):\n",
    "    return [preprocess_document(doc) for doc in documents]\n",
    "\n",
    "preprocessed_documents = preprocess_documents(anthology_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize lists to store embeddings\n",
    "# Initialize the MiniLM model for document embeddings\n",
    "# minilm_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "# Function to get document embedding using MiniLM\n",
    "# def get_document_embedding(document):\n",
    "#     return minilm_model.encode(document, convert_to_tensor=False)\n",
    "\n",
    "# minilm_embeddings = []\n",
    "\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get document embedding using MiniLM\n",
    "# def get_document_embedding(document):\n",
    "#     return minilm_model.encode(document, convert_to_tensor=False)\n",
    "\n",
    "# Function to get word embeddings using BERT and then aggregate them\n",
    "def get_aggregated_word_embeddings(document):\n",
    "    inputs = bert_tokenizer(document, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    word_embeddings = outputs.last_hidden_state.squeeze(0)  # Removing the batch dimension\n",
    "    aggregated_embedding = word_embeddings.mean(dim=0)  # Mean aggregation\n",
    "    return aggregated_embedding.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -c -L -O https://nlp.stanford.edu/data/glove.6B.zip\n",
    "# !curl -C -O https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load GloVe embeddings\n",
    "def load_glove_model(file_path):\n",
    "    model = {}\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            parts = line.split()\n",
    "            word = parts[0]\n",
    "            vector = np.array(parts[1:], dtype='float32')\n",
    "            model[word] = vector\n",
    "    return model\n",
    "\n",
    "glove_model = load_glove_model(\"glove.6B/glove.6B.100d.txt\")\n",
    "\n",
    "# Example words to embed\n",
    "# words = [\"example\", \"document\", \"word\", \"embedding\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None of the words in the input text are in the GloVe model.\n",
      "document: Translation Unit Concerning Timing Simultaneous Translation None None\n",
      "Processing doc: 100\n",
      "None of the words in the input text are in the GloVe model.\n",
      "document: Collection Evaluation Broadcast News Data {A}rabic None None\n",
      "Processing doc: 200\n",
      "None of the words in the input text are in the GloVe model.\n",
      "document: {E}nglish Speech Database Read {J}apanese Learners {CALL} System Development None None\n",
      "Processing doc: 300\n",
      "None of the words in the input text are in the GloVe model.\n",
      "document: Towards Use Word Stems Suffixes Statistical Machine Translation None None\n",
      "None of the words in the input text are in the GloVe model.\n",
      "document: Language Resource Creation Distribution {L}inguistic {D}ata {C}onsortium: Progress Report None None\n",
      "Processing doc: 400\n",
      "Processing doc: 500\n",
      "None of the words in the input text are in the GloVe model.\n",
      "document: 表示法學習技術於節錄式語音文件摘要之研究(A Study Representation Learning Techniques Extractive Spoken Document Summarization) [In {C}hinese] None None\n",
      "None of the words in the input text are in the GloVe model.\n",
      "document: Ellipsis Resolution Disguised Agent None None\n",
      "Processing doc: 600\n",
      "None of the words in the input text are in the GloVe model.\n",
      "document: Resolving Event Noun Phrases Verbal Mentions None\n",
      "None of the words in the input text are in the GloVe model.\n",
      "document: Logic-based Temporal Knowledge Representation {M}andarin {C}hinese None None\n",
      "Processing doc: 700\n",
      "None of the words in the input text are in the GloVe model.\n",
      "document: Many Uses, Many Annotations Large Speech Corpora: Switchboard {TDT} Case Studies None None\n",
      "Processing doc: 800\n",
      "Processing doc: 900\n",
      "None of the words in the input text are in the GloVe model.\n",
      "document: 動詞詞構與語法功能互動初探 (An Explorative Study Interaction Verb Compound Constructions Syntactic Functions) [In {C}hinese] None None\n",
      "None of the words in the input text are in the GloVe model.\n",
      "document: Practical Annotation Scheme {HPSG} Treebank {B}ulgarian None None\n",
      "Processing doc: 1000\n",
      "None of the words in the input text are in the GloVe model.\n",
      "document: Importance Evaluation Cross-Language System Development: {CLEF} Experience None None\n",
      "Processing doc: 1100\n"
     ]
    }
   ],
   "source": [
    "bert_embeddings = []\n",
    "glove_embeddings = []\n",
    "\n",
    "# Generate embeddings for each word\n",
    "def get_glove_word_embeddings(document):\n",
    "    word_embeddings = [glove_model[word] for word in document.split() if word in glove_model]\n",
    "    if not word_embeddings:\n",
    "        # raise ValueError(\"None of the words in the input text are in the GloVe model.\")\n",
    "\n",
    "        print(\"None of the words in the input text are in the GloVe model.\")\n",
    "        print(\"document:\",document)\n",
    "\n",
    "        zero_array = np.zeros(100, dtype=float) ### document didn't match any words from glove, hence returning zero array\n",
    "        document_embedding = zero_array\n",
    "    else:\n",
    "        document_embedding = np.mean(word_embeddings, axis=0)\n",
    "        # print(\"len:\", len(document_embedding))\n",
    "    return document_embedding\n",
    "\n",
    "# Compute embeddings for the first 1000 documents\n",
    "count = 1\n",
    "for document in preprocessed_documents[:]:\n",
    "    if count % 100 == 0:\n",
    "        print(\"Processing doc:\",count)\n",
    "    # Ensure the document is a string\n",
    "    document = str(document)\n",
    "    bert_embeddings.append(get_aggregated_word_embeddings(document))\n",
    "    we = get_glove_word_embeddings(document) ### HAD TO implement this check with we (word embeddings) as some of the documents had 0 hits on glove\n",
    "    glove_embeddings.append(we)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessed_documents = preprocess_documents(anthology_sample)\n",
    "# minilm_embeddings2 = [get_mpnet_embedding(doc) for doc in preprocessed_documents[:10]]  # Only first 1000 for k-NN\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# knn2 = NearestNeighbors(n_neighbors=5, metric='cosine').fit(minilm_embeddings)\n",
    "\n",
    "# Fit NearestNeighbors model\n",
    "nn_bert = NearestNeighbors(n_neighbors=5, metric='cosine', algorithm='brute')\n",
    "nn_bert.fit(bert_embeddings)\n",
    "nn_glove = NearestNeighbors(n_neighbors=5, metric='cosine', algorithm='brute')\n",
    "nn_glove.fit(glove_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Indices of nearest neighbors: [[ 307  998 1063  118  613]]\n",
      "BERT Distances to nearest neighbors: [[0.3178627  0.31918108 0.31948835 0.33049715 0.33055514]]\n",
      "Glove Indices of nearest neighbors: [[831 324 194 139 202]]\n",
      "Glove Distances to nearest neighbors: [[0.06632299 0.06715717 0.06814211 0.07119117 0.07293454]]\n"
     ]
    }
   ],
   "source": [
    "# Get embedding for the query sentence\n",
    "test_query = queries[\"queries\"][50]['q']\n",
    "test_query_bert_embed = get_aggregated_word_embeddings(test_query).reshape(1, -1)\n",
    "test_query_glove_embed = get_glove_word_embeddings(test_query).reshape(1, -1)\n",
    "\n",
    "\n",
    "distances_bert, indices_bert = nn_bert.kneighbors(test_query_bert_embed)\n",
    "# Print the indices and distances of the nearest neighbors\n",
    "print(\"BERT Indices of nearest neighbors:\", indices_bert)\n",
    "print(\"BERT Distances to nearest neighbors:\", distances_bert)\n",
    "\n",
    "distances_glove, indices_glove = nn_glove.kneighbors(test_query_glove_embed)\n",
    "\n",
    "# Print the indices and distances of the nearest neighbors\n",
    "print(\"Glove Indices of nearest neighbors:\", indices_glove)\n",
    "print(\"Glove Distances to nearest neighbors:\", distances_glove)\n",
    "\n",
    "# Print the nearest neighbor sentences\n",
    "# nearest_neighbors = [preprocessed_documents[idx] for idx in indices_glove[0]]\n",
    "# print(\"Nearest neighbor sentences:\", nearest_neighbors)\n",
    "# query_embedding2 = get_mpnet_embedding(test_query).reshape(1, -1)\n",
    "# distances, indices = knn2.kneighbors(query_embedding2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BELOW Cell is VERY IMPORTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth question: What is the name of the research initiative creating resources for African languages?\n",
      "Ground truth answer: Masakhane. (Masakha is also fine.)\n",
      "Ground truth references: ['2023.acl-long.796', '2023.acl-long.609', '2023.ijcnlp-main.10']\n",
      "OUR BERT references [['L14-1558', '2009.mtsummit-plenaries.7', '1993.eamt-1.15', 'L08-1141', 'L14-1106']]\n",
      "OUR Glove references [['L06-1176', 'L16-1719', '2022.semeval-1.0', '2023.acl-long.734', 'W15-4630']]\n"
     ]
    }
   ],
   "source": [
    "### Above results tell us following:\n",
    "print(\"Ground truth question:\", queries[\"queries\"][50]['q'])\n",
    "print(\"Ground truth answer:\", queries[\"queries\"][50]['a'])\n",
    "print(\"Ground truth references:\", queries[\"queries\"][50]['r'])\n",
    "print(\"OUR BERT references\", [anthology_sample[idx][\"acl_id\"] for idx in indices_bert])\n",
    "print(\"OUR Glove references\", [anthology_sample[idx][\"acl_id\"] for idx in indices_glove])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "## Retrieving the query\n",
    "# Function to retrieve the ground truth for a given query\n",
    "def get_ground_truth(query):\n",
    "    for q in queries[\"queries\"]:\n",
    "        if q[\"q\"] == query:\n",
    "            # return q[\"r\"]\n",
    "            return [r for r in q[\"r\"]]\n",
    "    return None\n",
    "# ground_truth = get_ground_truth(query)\n",
    "\n",
    "# Function to compare the result with the ground truth for a single query\n",
    "# Function to calculate average precision for a single query\n",
    "def average_precision(retrieved_docs, ground_truth_ids):\n",
    "    if not ground_truth_ids:\n",
    "        return 0\n",
    "    retrieved_docs_set = set(retrieved_docs)\n",
    "    ground_truth_set = set(ground_truth_ids)\n",
    "    \n",
    "    num_relevant = 0\n",
    "    precision_sum = 0\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        if doc in ground_truth_set:\n",
    "            num_relevant += 1\n",
    "            precision_sum += num_relevant / (i + 1)\n",
    "    \n",
    "    return precision_sum / len(ground_truth_set)\n",
    "\n",
    "# Function to compare the result with the ground truth for a single query\n",
    "def compare_with_ground_truth(query_text, nn_model, dataset, ground_truth_function, k,get_embeddings_func):\n",
    "    # print(\"cgt k=\",k)\n",
    "    # Get nearest neighbors\n",
    "    indices = get_nearest_neighbors(query_text, nn_model, k,get_embeddings_func)\n",
    "    \n",
    "    # Convert numpy.int64 to Python int\n",
    "    indices = [int(i) for i in indices]\n",
    "    \n",
    "    # Retrieve document IDs for nearest neighbors\n",
    "    retrieved_docs = [dataset[i]['acl_id'] for i in indices]\n",
    "    \n",
    "    # Get ground truth\n",
    "    ground_truth_ids = ground_truth_function(query_text)\n",
    "    \n",
    "    if not ground_truth_ids:\n",
    "        return 0, 0, 0, 0, 0, 0, 0  # Return zeros if no ground truth is available\n",
    "    \n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    tp = len(set(retrieved_docs) & set(ground_truth_ids))\n",
    "    fp = len(retrieved_docs) - tp\n",
    "    fn = len(ground_truth_ids) - tp\n",
    "    \n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = tp / len(retrieved_docs) if retrieved_docs else 0\n",
    "    recall = tp / len(ground_truth_ids) if ground_truth_ids else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "    \n",
    "    # Calculate average precision\n",
    "    ap = average_precision(retrieved_docs, ground_truth_ids)\n",
    "    \n",
    "    return precision, recall, f1, ap, tp, fp, fn\n",
    "\n",
    "# Function to evaluate the model on all queries\n",
    "def evaluate_model_on_all_queries(queries, embeddings, dataset, ground_truth_function, k, get_embeddings_func):\n",
    "    # Fit NearestNeighbors model\n",
    "    print(\"k=\",k)\n",
    "    nn = NearestNeighbors(n_neighbors=k, metric='cosine', algorithm='brute')\n",
    "    nn.fit(embeddings)\n",
    "\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    ap_scores = []\n",
    "    total_tp = total_fp = total_fn = 0\n",
    "\n",
    "    for query in queries[\"queries\"]:\n",
    "        query_text = query[\"q\"]\n",
    "        precision, recall, f1, ap, tp, fp, fn = compare_with_ground_truth(query_text, nn, dataset, ground_truth_function, k,get_embeddings_func)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        ap_scores.append(ap)\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "    \n",
    "    # Calculate macro average metrics\n",
    "    macro_precision = np.mean(precision_scores)\n",
    "    macro_recall = np.mean(recall_scores)\n",
    "    macro_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    # Calculate micro average metrics\n",
    "    micro_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) else 0\n",
    "    micro_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) else 0\n",
    "    micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall) if (micro_precision + micro_recall) else 0\n",
    "    \n",
    "    # Calculate mean AP\n",
    "    mean_ap = np.mean(ap_scores)\n",
    "    \n",
    "    return macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1, mean_ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_neighbors(query_text, nn_model, k, get_embeddings_func):\n",
    "    # query_embedding = get_aggregated_word_embeddings([query_text])\n",
    "    # print(query_text)\n",
    "    # test_query_word_embed = get_aggregated_word_embeddings(query_text).reshape(1, -1)\n",
    "    test_query_word_embed = get_embeddings_func(query_text).reshape(1, -1)\n",
    "    distances, indices = nn_model.kneighbors(test_query_word_embed, n_neighbors=k)\n",
    "    return indices[0]\n",
    "\n",
    "def get_bert_nearest_neighbors(query_text, nn_model, k):\n",
    "    # query_embedding = get_aggregated_word_embeddings([query_text])\n",
    "    # print(query_text)\n",
    "    # test_query_word_embed = get_aggregated_word_embeddings(query_text).reshape(1, -1)\n",
    "    test_query_word_embed = get_aggregated_word_embeddings(query_text).reshape(1, -1)\n",
    "    distances, indices = nn_model.kneighbors(test_query_word_embed, n_neighbors=k)\n",
    "    return indices[0]\n",
    "\n",
    "def get_glove_nearest_neighbors(query_text, nn_model, k):\n",
    "    # query_embedding = get_aggregated_word_embeddings([query_text])\n",
    "    # print(query_text)\n",
    "    # test_query_word_embed = get_aggregated_word_embeddings(query_text).reshape(1, -1)\n",
    "    test_query_word_embed =  get_glove_word_embeddings(query_text).reshape(1, -1)\n",
    "    distances, indices = nn_model.kneighbors(test_query_word_embed, n_neighbors=k)\n",
    "    return indices[0]\n",
    "    \n",
    "def nearest_neighbour(embeddings): # can be tfidf_matrix or LSI_matrix doesnt\n",
    "    nn = NearestNeighbors(n_neighbors=1, metric='cosine',algorithm = 'brute')\n",
    "    nn.fit(embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS when summarizing preprocessing text using ntlk library and BertModel.from_pretrained('bert-base-uncased') for word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 5\n",
      "Macro Average Precision: 0.0020\n",
      "Macro Average Recall: 0.0102\n",
      "Macro Average F1-Score: 0.0034\n",
      "Micro Average Precision: 0.0020\n",
      "Micro Average Recall: 0.0058\n",
      "Micro Average F1-Score: 0.0030\n",
      "Mean Average Precision (mAP): 0.0051\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1, mean_ap = evaluate_model_on_all_queries(queries, bert_embeddings, anthology_sample, get_ground_truth, k,get_embeddings_func=get_aggregated_word_embeddings )\n",
    "print(f\"Macro Average Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Average Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro Average F1-Score: {macro_f1:.4f}\")\n",
    "print(f\"Micro Average Precision: {micro_precision:.4f}\")\n",
    "print(f\"Micro Average Recall: {micro_recall:.4f}\")\n",
    "print(f\"Micro Average F1-Score: {micro_f1:.4f}\")\n",
    "print(f\"Mean Average Precision (mAP): {mean_ap:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 5\n",
      "Macro Average Precision: 0.0102\n",
      "Macro Average Recall: 0.0374\n",
      "Macro Average F1-Score: 0.0153\n",
      "Micro Average Precision: 0.0102\n",
      "Micro Average Recall: 0.0291\n",
      "Micro Average F1-Score: 0.0151\n",
      "Mean Average Precision (mAP): 0.0323\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1, mean_ap = evaluate_model_on_all_queries(queries, glove_embeddings, anthology_sample, get_ground_truth, k,get_embeddings_func=get_glove_word_embeddings)\n",
    "print(f\"Macro Average Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Average Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro Average F1-Score: {macro_f1:.4f}\")\n",
    "print(f\"Micro Average Precision: {micro_precision:.4f}\")\n",
    "print(f\"Micro Average Recall: {micro_recall:.4f}\")\n",
    "print(f\"Micro Average F1-Score: {micro_f1:.4f}\")\n",
    "print(f\"Mean Average Precision (mAP): {mean_ap:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "CHROMA_DATA_PATH = \"chroma_data/\"\n",
    "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "COLLECTION_NAME = \"demo_docs\"\n",
    "client = chromadb.PersistentClient(path=CHROMA_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "...     model_name=EMBED_MODEL\n",
    "... )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_texts = [f'{d[\"full_text\"]}' for d in anthology_sample]\n",
    "abstracts = [f'{d[\"abstract\"]}' for d in anthology_sample]\n",
    "ids=[f\"{i}\" for i in range(len(anthology_sample))]\n",
    "acl_ids = [f'acl_id:{d[\"acl_id\"]}' for d in anthology_sample]\n",
    "authors=[{\"author\":{d[\"author\"]}} for d in anthology_sample]\n",
    "# collection.add(documents=preprocessed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.create_collection(\n",
    "...     name=COLLECTION_NAME,\n",
    "...     embedding_function=embedding_func,\n",
    "...     metadata={\"hnsw:space\": \"cosine\"},\n",
    "... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "...     documents=preprocessed_documents,\n",
    "...     ids=ids,\n",
    "# ...     metadatas=authors\n",
    "... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = collection.query(\n",
    "...     query_texts=[\"What is the name of the research initiative creating resources for African languages?\"],\n",
    "...     n_results=5,\n",
    "... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These are the search results on example question (queries[\"queries\"][50]) using ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L14-1106\n",
      "2023.sigtyp-1.17\n",
      "L16-1719\n",
      "2021.mrl-1.11\n",
      "W14-2212\n"
     ]
    }
   ],
   "source": [
    "# query_results[\"ids\"][0]\n",
    "\n",
    "for id in query_results[\"ids\"][0]:\n",
    "    print(anthology_sample[int(id)][\"acl_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here are our results for the same question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUR BERT references [['L14-1558', '2009.mtsummit-plenaries.7', '1993.eamt-1.15', 'L08-1141', 'L14-1106']]\n",
      "OUR Glove references [['L06-1176', 'L16-1719', '2022.semeval-1.0', '2023.acl-long.734', 'W15-4630']]\n"
     ]
    }
   ],
   "source": [
    "print(\"OUR BERT references\", [anthology_sample[idx][\"acl_id\"] for idx in indices_bert])\n",
    "print(\"OUR Glove references\", [anthology_sample[idx][\"acl_id\"] for idx in indices_glove])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground truth for the same query (q50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth question: What is the name of the research initiative creating resources for African languages?\n",
      "Ground truth answer: Masakhane. (Masakha is also fine.)\n",
      "Ground truth references: ['2023.acl-long.796', '2023.acl-long.609', '2023.ijcnlp-main.10']\n"
     ]
    }
   ],
   "source": [
    "print(\"Ground truth question:\", queries[\"queries\"][50]['q'])\n",
    "print(\"Ground truth answer:\", queries[\"queries\"][50]['a'])\n",
    "print(\"Ground truth references:\", queries[\"queries\"][50]['r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: It seems that our word transformers have low performance due to lack of context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
