{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2de9d54d8d43dc8f24f23fb6f8c7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "27259830"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import datasets\n",
    "\n",
    "\n",
    "# R_NUMBER_SEED = 1234567 # Replace this with your own student number\n",
    "R_NUMBER_SEED = 928036 # my student number \n",
    "DOCS_TO_ADD = 1000\n",
    "query_documents = datasets.load_dataset(\"parquet\", data_files=\"./acl_anthology_queries.parquet\")[\"train\"]\n",
    "all_documents = datasets.load_dataset(\"parquet\", data_files=\"./acl_anthology_full.parquet\")[\"train\"]\n",
    "# Shuffle with seed and take only n docs\n",
    "shuffled_documents = all_documents.shuffle(seed=R_NUMBER_SEED)\n",
    "random_documents = shuffled_documents.select(range(DOCS_TO_ADD))\n",
    "# Concatenate relevant documents with random sample and shuffle again\n",
    "anthology_sample = datasets.concatenate_datasets([query_documents, random_documents]).shuffle(seed=R_NUMBER_SEED)\n",
    "# Export to Parquet to avoid downloading full anthology\n",
    "anthology_sample.to_parquet(\"./anthology_sample.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "queries = json.load(open(\"./acl_anthology_queries.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/marko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "# def remove_stopwords(doc):\n",
    "#     text = ' '.join([word for word in doc.split() if word.lower() not in stop_words])\n",
    "\n",
    "# def preprocess_document(doc):\n",
    "#     # Flatten dictionary and combine relevant text fields\n",
    "#     text = f\"{doc.get('title', '')} {doc.get('abstract', '')} {doc.get('full_text', '')}\"\n",
    "    \n",
    "#     # Remove stopwords\n",
    "#     text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    \n",
    "#     return text\n",
    "\n",
    "# def preprocess_documents(documents):\n",
    "#     return [preprocess_document(doc) for doc in documents]\n",
    "\n",
    "# preprocessed_documents = preprocess_documents(anthology_sample)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/marko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: 10\n",
      "doc: 20\n",
      "doc: 30\n",
      "doc: 40\n",
      "doc: 50\n",
      "doc: 60\n",
      "doc: 70\n",
      "doc: 80\n",
      "doc: 90\n",
      "doc: 100\n",
      "doc: 110\n",
      "doc: 120\n",
      "doc: 130\n",
      "doc: 140\n",
      "doc: 150\n",
      "doc: 160\n",
      "doc: 170\n",
      "doc: 180\n",
      "doc: 190\n",
      "doc: 200\n",
      "doc: 210\n",
      "doc: 220\n",
      "doc: 230\n",
      "doc: 240\n",
      "doc: 250\n",
      "doc: 260\n",
      "doc: 270\n",
      "doc: 280\n",
      "doc: 290\n",
      "doc: 300\n",
      "doc: 310\n",
      "doc: 320\n",
      "doc: 330\n",
      "doc: 340\n",
      "doc: 350\n",
      "doc: 360\n",
      "doc: 370\n",
      "doc: 380\n",
      "doc: 390\n",
      "doc: 400\n",
      "doc: 410\n",
      "doc: 420\n",
      "doc: 430\n",
      "doc: 440\n",
      "doc: 450\n",
      "doc: 460\n",
      "doc: 470\n",
      "doc: 480\n",
      "doc: 490\n",
      "doc: 500\n",
      "doc: 510\n",
      "doc: 520\n",
      "doc: 530\n",
      "doc: 540\n",
      "doc: 550\n",
      "doc: 560\n",
      "doc: 570\n",
      "doc: 580\n",
      "doc: 590\n",
      "doc: 600\n",
      "doc: 610\n",
      "doc: 620\n",
      "doc: 630\n",
      "doc: 640\n",
      "doc: 650\n",
      "doc: 660\n",
      "doc: 670\n",
      "doc: 680\n",
      "doc: 690\n",
      "doc: 700\n",
      "doc: 710\n",
      "doc: 720\n",
      "doc: 730\n",
      "doc: 740\n",
      "doc: 750\n",
      "doc: 760\n",
      "doc: 770\n",
      "doc: 780\n",
      "doc: 790\n",
      "doc: 800\n",
      "doc: 810\n",
      "doc: 820\n",
      "doc: 830\n",
      "doc: 840\n",
      "doc: 850\n",
      "doc: 860\n",
      "doc: 870\n",
      "doc: 880\n",
      "doc: 890\n",
      "doc: 900\n",
      "doc: 910\n",
      "doc: 920\n",
      "doc: 930\n",
      "doc: 940\n",
      "doc: 950\n",
      "doc: 960\n",
      "doc: 970\n",
      "doc: 980\n",
      "doc: 990\n",
      "doc: 1000\n",
      "doc: 1010\n",
      "doc: 1020\n",
      "doc: 1030\n",
      "doc: 1040\n",
      "doc: 1050\n",
      "doc: 1060\n",
      "doc: 1070\n",
      "doc: 1080\n",
      "doc: 1090\n",
      "doc: 1100\n",
      "doc: 1110\n",
      "doc: 1120\n",
      "doc: 1130\n",
      "doc: 1140\n",
      "doc: 1150\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def preprocess_documents_nltk(documents):\n",
    "    all_sentences = []\n",
    "    all_sentences_to_doc_map = []\n",
    "    count = 1\n",
    "    for doc in documents:\n",
    "        if count % 10 == 0:\n",
    "            print(\"doc:\",count)\n",
    "        # print(doc[\"acl_id\"])\n",
    "        # full_text = f\"{doc.get('full_text')}\"\n",
    "        full_text = \"\"\n",
    "        if doc[\"title\"] is not None: full_text = f'{doc[\"title\"]}.' \n",
    "        if doc[\"abstract\"] is not None: full_text = f'{full_text} {doc[\"abstract\"]}.' \n",
    "        if doc[\"full_text\"] is not None: full_text = f'{full_text} {doc[\"full_text\"]}.' \n",
    "        sentences = sent_tokenize(full_text)\n",
    "        for sentence in sentences:\n",
    "            all_sentences.append(sentence)\n",
    "            all_sentences_to_doc_map.append(doc[\"acl_id\"])\n",
    "        count += 1\n",
    "    return all_sentences,all_sentences_to_doc_map\n",
    "preprocessed_documents, sentence_to_doc_map = preprocess_documents_nltk(anthology_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize lists to store embeddings\n",
    "# Initialize the MiniLM model for document embeddings\n",
    "minilm_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "# Function to get document embedding using MiniLM\n",
    "def get_document_embedding(document):\n",
    "    return minilm_model.encode(document, convert_to_tensor=False)\n",
    "\n",
    "minilm_embeddings = []\n",
    "# bert_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192757"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(document)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(\"Processing sentence embeddings:\",count)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m indexes\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdocument\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43macl_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     11\u001b[0m count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# Compute embeddings for the first 1000 documents\n",
    "indexes = []\n",
    "count = 1\n",
    "for document in preprocessed_documents[:10000]:\n",
    "    if count % 100 == 0:\n",
    "        print(\"Processing doc:\",count)\n",
    "    # Ensure the document is a string\n",
    "    document = str(document)\n",
    "    # print(\"Processing sentence embeddings:\",count)\n",
    "    indexes.append(document[\"acl_id\"])\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing doc: 100\n",
      "Processing doc: 200\n",
      "Processing doc: 300\n",
      "Processing doc: 400\n",
      "Processing doc: 500\n",
      "Processing doc: 600\n",
      "Processing doc: 700\n",
      "Processing doc: 800\n",
      "Processing doc: 900\n",
      "Processing doc: 1000\n",
      "Processing doc: 1100\n",
      "Processing doc: 1200\n",
      "Processing doc: 1300\n",
      "Processing doc: 1400\n",
      "Processing doc: 1500\n",
      "Processing doc: 1600\n",
      "Processing doc: 1700\n",
      "Processing doc: 1800\n",
      "Processing doc: 1900\n",
      "Processing doc: 2000\n",
      "Processing doc: 2100\n",
      "Processing doc: 2200\n",
      "Processing doc: 2300\n",
      "Processing doc: 2400\n",
      "Processing doc: 2500\n",
      "Processing doc: 2600\n",
      "Processing doc: 2700\n",
      "Processing doc: 2800\n",
      "Processing doc: 2900\n",
      "Processing doc: 3000\n",
      "Processing doc: 3100\n",
      "Processing doc: 3200\n",
      "Processing doc: 3300\n",
      "Processing doc: 3400\n",
      "Processing doc: 3500\n",
      "Processing doc: 3600\n",
      "Processing doc: 3700\n",
      "Processing doc: 3800\n",
      "Processing doc: 3900\n",
      "Processing doc: 4000\n",
      "Processing doc: 4100\n",
      "Processing doc: 4200\n",
      "Processing doc: 4300\n",
      "Processing doc: 4400\n",
      "Processing doc: 4500\n",
      "Processing doc: 4600\n",
      "Processing doc: 4700\n",
      "Processing doc: 4800\n",
      "Processing doc: 4900\n",
      "Processing doc: 5000\n",
      "Processing doc: 5100\n",
      "Processing doc: 5200\n",
      "Processing doc: 5300\n",
      "Processing doc: 5400\n",
      "Processing doc: 5500\n",
      "Processing doc: 5600\n",
      "Processing doc: 5700\n",
      "Processing doc: 5800\n",
      "Processing doc: 5900\n",
      "Processing doc: 6000\n",
      "Processing doc: 6100\n",
      "Processing doc: 6200\n",
      "Processing doc: 6300\n",
      "Processing doc: 6400\n",
      "Processing doc: 6500\n",
      "Processing doc: 6600\n",
      "Processing doc: 6700\n",
      "Processing doc: 6800\n",
      "Processing doc: 6900\n",
      "Processing doc: 7000\n",
      "Processing doc: 7100\n",
      "Processing doc: 7200\n",
      "Processing doc: 7300\n",
      "Processing doc: 7400\n",
      "Processing doc: 7500\n",
      "Processing doc: 7600\n",
      "Processing doc: 7700\n",
      "Processing doc: 7800\n",
      "Processing doc: 7900\n",
      "Processing doc: 8000\n",
      "Processing doc: 8100\n",
      "Processing doc: 8200\n",
      "Processing doc: 8300\n",
      "Processing doc: 8400\n",
      "Processing doc: 8500\n",
      "Processing doc: 8600\n",
      "Processing doc: 8700\n",
      "Processing doc: 8800\n",
      "Processing doc: 8900\n",
      "Processing doc: 9000\n",
      "Processing doc: 9100\n",
      "Processing doc: 9200\n",
      "Processing doc: 9300\n",
      "Processing doc: 9400\n",
      "Processing doc: 9500\n",
      "Processing doc: 9600\n",
      "Processing doc: 9700\n",
      "Processing doc: 9800\n",
      "Processing doc: 9900\n",
      "Processing doc: 10000\n"
     ]
    }
   ],
   "source": [
    "# Compute embeddings for the first 1000 documents\n",
    "count = 1\n",
    "for document in preprocessed_documents[:10000]:\n",
    "    if count % 100 == 0:\n",
    "        print(\"Processing doc:\",count)\n",
    "    # Ensure the document is a string\n",
    "    document = str(document)\n",
    "    # print(\"Processing sentence embeddings:\",count)\n",
    "    minilm_embeddings.append(get_document_embedding(document))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessed_documents = preprocess_documents(anthology_sample)\n",
    "# minilm_embeddings2 = [get_mpnet_embedding(doc) for doc in preprocessed_documents[:10]]  # Only first 1000 for k-NN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# knn2 = NearestNeighbors(n_neighbors=5, metric='cosine').fit(minilm_embeddings)\n",
    "\n",
    "# Fit NearestNeighbors model\n",
    "nn_minilm = NearestNeighbors(n_neighbors=5, metric='cosine', algorithm='brute')\n",
    "nn_minilm.fit(minilm_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [[3369 5638 9890 7857 6206]]\n",
      "Distances to nearest neighbors: [[0.5237292  0.52388525 0.52864885 0.52961564 0.5762628 ]]\n"
     ]
    }
   ],
   "source": [
    "# Get embedding for the query sentence\n",
    "test_query = queries[\"queries\"][18]['q']\n",
    "test_query_sen_embed = get_document_embedding(test_query).reshape(1, -1)\n",
    "# get_nearest_neighbors(test_query_sen_embed,nn_minilm,1)\n",
    "# get_document_embedding\n",
    "\n",
    "distances, indices = nn_minilm.kneighbors(test_query_sen_embed)\n",
    "\n",
    "# Print the indices and distances of the nearest neighbors\n",
    "print(\"Indices of nearest neighbors:\", indices)\n",
    "print(\"Distances to nearest neighbors:\", distances)\n",
    "\n",
    "# Print the nearest neighbor sentences\n",
    "nearest_neighbors = [preprocessed_documents[idx] for idx in indices[0]]\n",
    "# print(\"Nearest neighbor sentences:\", nearest_neighbors)\n",
    "# query_embedding2 = get_mpnet_embedding(test_query).reshape(1, -1)\n",
    "# distances, indices = knn2.kneighbors(query_embedding2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BELOW Cell is VERY IMPORTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth question: What is the name of the research initiative creating resources for African languages?\n",
      "Ground truth answer: Masakhane. (Masakha is also fine.)\n",
      "Ground truth references: ['2023.acl-long.796', '2023.acl-long.609', '2023.ijcnlp-main.10']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Invalid key: 9890 is out of bounds for size 1153",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGround truth answer:\u001b[39m\u001b[38;5;124m\"\u001b[39m, queries[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m50\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGround truth references:\u001b[39m\u001b[38;5;124m\"\u001b[39m, queries[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m50\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUR references\u001b[39m\u001b[38;5;124m\"\u001b[39m, [anthology_sample[idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macl_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])\n",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGround truth answer:\u001b[39m\u001b[38;5;124m\"\u001b[39m, queries[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m50\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGround truth references:\u001b[39m\u001b[38;5;124m\"\u001b[39m, queries[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m50\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUR references\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[43manthology_sample\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macl_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])\n",
      "File \u001b[0;32m~/virt/py310/lib/python3.10/site-packages/datasets/arrow_dataset.py:2810\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virt/py310/lib/python3.10/site-packages/datasets/arrow_dataset.py:2794\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2792\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   2793\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2794\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2795\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[1;32m   2796\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[1;32m   2797\u001b[0m )\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/virt/py310/lib/python3.10/site-packages/datasets/formatting/formatting.py:583\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     size \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mnum_rows \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m table\u001b[38;5;241m.\u001b[39mnum_rows\n\u001b[0;32m--> 583\u001b[0m     \u001b[43m_check_valid_index_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# Query the main table\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/virt/py310/lib/python3.10/site-packages/datasets/formatting/formatting.py:536\u001b[0m, in \u001b[0;36m_check_valid_index_key\u001b[0;34m(key, size)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Iterable):\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 536\u001b[0m         \u001b[43m_check_valid_index_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m         _check_valid_index_key(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(key)), size\u001b[38;5;241m=\u001b[39msize)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/virt/py310/lib/python3.10/site-packages/datasets/formatting/formatting.py:526\u001b[0m, in \u001b[0;36m_check_valid_index_key\u001b[0;34m(key, size)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m+\u001b[39m size \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m size):\n\u001b[0;32m--> 526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is out of bounds for size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n",
      "\u001b[0;31mIndexError\u001b[0m: Invalid key: 9890 is out of bounds for size 1153"
     ]
    }
   ],
   "source": [
    "### Above results tell us following:\n",
    "print(\"Ground truth question:\", queries[\"queries\"][50]['q'])\n",
    "print(\"Ground truth answer:\", queries[\"queries\"][50]['a'])\n",
    "print(\"Ground truth references:\", queries[\"queries\"][50]['r'])\n",
    "print(\"OUR references\", [anthology_sample[idx][\"acl_id\"] for idx in indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Retrieving the query\n",
    "# Function to retrieve the ground truth for a given query\n",
    "def get_ground_truth(query):\n",
    "    for q in queries[\"queries\"]:\n",
    "        if q[\"q\"] == query:\n",
    "            # return q[\"r\"]\n",
    "            return [r for r in q[\"r\"]]\n",
    "    return None\n",
    "# ground_truth = get_ground_truth(query)\n",
    "\n",
    "# Function to compare the result with the ground truth for a single query\n",
    "# Function to calculate average precision for a single query\n",
    "def average_precision(retrieved_docs, ground_truth_ids):\n",
    "    if not ground_truth_ids:\n",
    "        return 0\n",
    "    retrieved_docs_set = set(retrieved_docs)\n",
    "    ground_truth_set = set(ground_truth_ids)\n",
    "    \n",
    "    num_relevant = 0\n",
    "    precision_sum = 0\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        if doc in ground_truth_set:\n",
    "            num_relevant += 1\n",
    "            precision_sum += num_relevant / (i + 1)\n",
    "    \n",
    "    return precision_sum / len(ground_truth_set)\n",
    "\n",
    "# Function to compare the result with the ground truth for a single query\n",
    "def compare_with_ground_truth(query_text, nn_model, dataset, ground_truth_function, k):\n",
    "    # print(\"cgt k=\",k)\n",
    "    # Get nearest neighbors\n",
    "    indices = get_nearest_neighbors(query_text, nn_model, k)\n",
    "    \n",
    "    # Convert numpy.int64 to Python int\n",
    "    indices = [int(i) for i in indices]\n",
    "    \n",
    "    # Retrieve document IDs for nearest neighbors\n",
    "    retrieved_docs = [dataset[i]['acl_id'] for i in indices]\n",
    "    \n",
    "    # Get ground truth\n",
    "    ground_truth_ids = ground_truth_function(query_text)\n",
    "    \n",
    "    if not ground_truth_ids:\n",
    "        return 0, 0, 0, 0, 0, 0, 0  # Return zeros if no ground truth is available\n",
    "    \n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    tp = len(set(retrieved_docs) & set(ground_truth_ids))\n",
    "    fp = len(retrieved_docs) - tp\n",
    "    fn = len(ground_truth_ids) - tp\n",
    "    \n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = tp / len(retrieved_docs) if retrieved_docs else 0\n",
    "    recall = tp / len(ground_truth_ids) if ground_truth_ids else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "    \n",
    "    # Calculate average precision\n",
    "    ap = average_precision(retrieved_docs, ground_truth_ids)\n",
    "    \n",
    "    return precision, recall, f1, ap, tp, fp, fn\n",
    "\n",
    "# Function to evaluate the model on all queries\n",
    "def evaluate_model_on_all_queries(queries, embeddings, dataset, ground_truth_function, k):\n",
    "    # Fit NearestNeighbors model\n",
    "    print(\"k=\",k)\n",
    "    nn = NearestNeighbors(n_neighbors=k, metric='cosine', algorithm='brute')\n",
    "    nn.fit(embeddings)\n",
    "\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    ap_scores = []\n",
    "    total_tp = total_fp = total_fn = 0\n",
    "\n",
    "    for query in queries[\"queries\"]:\n",
    "        query_text = query[\"q\"]\n",
    "        precision, recall, f1, ap, tp, fp, fn = compare_with_ground_truth(query_text, nn, dataset, ground_truth_function, k)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        ap_scores.append(ap)\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "    \n",
    "    # Calculate macro average metrics\n",
    "    macro_precision = np.mean(precision_scores)\n",
    "    macro_recall = np.mean(recall_scores)\n",
    "    macro_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    # Calculate micro average metrics\n",
    "    micro_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) else 0\n",
    "    micro_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) else 0\n",
    "    micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall) if (micro_precision + micro_recall) else 0\n",
    "    \n",
    "    # Calculate mean AP\n",
    "    mean_ap = np.mean(ap_scores)\n",
    "    \n",
    "    return macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1, mean_ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_neighbors(query_text, nn_model, k):\n",
    "    # query_embedding = get_aggregated_word_embeddings([query_text])\n",
    "    # print(query_text)\n",
    "    # test_query_word_embed = get_aggregated_word_embeddings(query_text).reshape(1, -1)\n",
    "    test_query_word_embed = get_document_embedding(query_text).reshape(1, -1)\n",
    "    distances, indices = nn_model.kneighbors(test_query_word_embed, n_neighbors=k)\n",
    "    return indices[0]\n",
    "\n",
    "def nearest_neighbour(embeddings): # can be tfidf_matrix or LSI_matrix doesnt\n",
    "    nn = NearestNeighbors(n_neighbors=1, metric='cosine',algorithm = 'brute')\n",
    "    nn.fit(embeddings)\n",
    "    \n",
    "# test_query = queries[\"queries\"][0]['q']\n",
    "# get_nearest_neighbors(test_query,nn_minilm,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS when summarizing preprocessing text using ntlk library and minilm_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2') for sentence embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1, mean_ap = evaluate_model_on_all_queries(queries, minilm_embeddings, anthology_sample, get_ground_truth, k)\n",
    "print(f\"Macro Average Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Average Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro Average F1-Score: {macro_f1:.4f}\")\n",
    "print(f\"Micro Average Precision: {micro_precision:.4f}\")\n",
    "print(f\"Micro Average Recall: {micro_recall:.4f}\")\n",
    "print(f\"Micro Average F1-Score: {micro_f1:.4f}\")\n",
    "print(f\"Mean Average Precision (mAP): {mean_ap:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "\n",
    "CHROMA_DATA_PATH = \"chroma_data/\"\n",
    "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "COLLECTION_NAME = \"demo_docs\"\n",
    "client = chromadb.PersistentClient(path=CHROMA_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "...     model_name=EMBED_MODEL\n",
    "... )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_texts = [f'{d[\"full_text\"]}' for d in anthology_sample]\n",
    "abstracts = [f'{d[\"abstract\"]}' for d in anthology_sample]\n",
    "ids=[f\"{i}\" for i in range(len(anthology_sample))]\n",
    "acl_ids = [f'acl_id:{d[\"acl_id\"]}' for d in anthology_sample]\n",
    "authors=[{\"author\":{d[\"author\"]}} for d in anthology_sample]\n",
    "# collection.add(documents=preprocessed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.create_collection(\n",
    "...     name=COLLECTION_NAME,\n",
    "...     embedding_function=embedding_func,\n",
    "...     metadata={\"hnsw:space\": \"cosine\"},\n",
    "... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "...     documents=preprocessed_documents,\n",
    "...     ids=ids,\n",
    "# ...     metadatas=authors\n",
    "... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = collection.query(\n",
    "...     query_texts=[\"What is the name of the research initiative creating resources for African languages?\"],\n",
    "...     n_results=5,\n",
    "... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These are the search results on example question (queries[\"queries\"][50]) using ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_results[\"ids\"][0]\n",
    "\n",
    "for id in query_results[\"ids\"][0]:\n",
    "    print(anthology_sample[int(id)][\"acl_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here are our results for the same question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OUR references\", [anthology_sample[idx][\"acl_id\"] for idx in indices])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground truth for the same query (q50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ground truth question:\", queries[\"queries\"][50]['q'])\n",
    "print(\"Ground truth answer:\", queries[\"queries\"][50]['a'])\n",
    "print(\"Ground truth references:\", queries[\"queries\"][50]['r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: It seems that our sentence transformer provides closer matches to the ground truth than results from ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = queries[\"queries\"][50]\n",
    "user_prompt = queries[\"queries\"][50][\"q\"]\n",
    "user_prompt= \"Which subword tokenizers can be trained with semi-supervised data?\"\n",
    "user_prompt = queries[\"queries\"][97][\"q\"]\n",
    "\n",
    "# for hit in hits:\n",
    "#   print(hit.payload, \"score:\", hit.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = nn_minilm.kneighbors(get_document_embedding(user_prompt).reshape(1, -1))\n",
    "distances, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for i,cosine in enumerate(distances):\n",
    "    acl_anthology_index = sentence_to_doc_map[indices[0][i]]\n",
    "    # matches.append(anthology_sample[int(indices[0][i])])\n",
    "    matches.append(anthology_sample[acl_anthology_index])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p = f\"{user_prompt} Can you cite-in the authors that are present in this document ?\"\n",
    "\n",
    "# Now time to connect to the local large language model\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"http://127.0.0.1:8080/v1\", # \"http://<Your api-server IP>:port\"\n",
    "    api_key = \"sk-no-key-required\"\n",
    ")\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"LLaMA_CPP\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistance an assistant designed to help answer questions related to academic research. Your top priority is to help users answer what are the matching documents.\"},\n",
    "        {\"role\": \"user\", \"content\": user_p},\n",
    "        {\"role\": \"assistant\", \"content\": str(matches)}\n",
    "    ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,doc in enumerate(anthology_sample):\n",
    "    # print(doc[\"acl_id\"])\n",
    "    if \"L16-1030\" in doc[\"acl_id\"]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,q in enumerate(queries[\"queries\"]):\n",
    "    print(q[\"r\"])\n",
    "    if \"L16-1030\" in q[\"r\"]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
